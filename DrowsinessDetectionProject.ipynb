{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "\n",
    "# # Skeleton base for starting a webcam and keeping it alive until key interrupt\n",
    "# # is given\n",
    "# cap = cv2.VideoCapture(0) # 0 for default camera of the machine (PC)\n",
    "\n",
    "# while True:\n",
    "#     _, frame = cap.read()\n",
    "#     frame = cv2.flip(frame, 1) # mirror the webcam (1 - flip vertically)\n",
    "\n",
    "#     greyScale = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     cv2.imshow(\"Drowsiness Detection System\", frame)\n",
    "#     key = cv2.waitKey(10) # returns the ASCII value of the key pressed\n",
    "\n",
    "#     # Esc, 'Q', or 'q' exits the webcam\n",
    "#     # ord() returns the ASCII value of the parameter\n",
    "#     if key in [27, ord('q'), ord('Q')]:\n",
    "#         break\n",
    "# # end while\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "\n",
    "# Face detection or mapping face to get eyes\n",
    "faceDetector = dlib.get_frontal_face_detector()\n",
    "\n",
    "# Put the location of .DAT file for predicting the landmarks on face\n",
    "pathToDotDATFile = \"shape_predictor_68_face_landmarks\\ \\\n",
    "    shape_predictor_68_face_landmarks.dat\"\n",
    "pathToDotDATFile = \"\".join(pathToDotDATFile.split())\n",
    "\n",
    "dlibFaceLandmark = dlib.shape_predictor(pathToDotDATFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Face Landmark Mapping Points\n",
    "The image below shows all the masking and landmarks numerically.\n",
    "\n",
    "![Face Mask Image](images\\facemask.png \"Face Mask Image\")\n",
    "\n",
    "The landmarks are numbered from 0-67. The landmarks are mapped as follows:\n",
    "- 0-16: Jawline\n",
    "- 17-21: Right Eyebrow\n",
    "- 22-26: Left Eyebrow\n",
    "- 27-30: Nose Bridge\n",
    "- 30-35: Lower Nose\n",
    "- 36-41: Right Eye\n",
    "- 42-47: Left Eye\n",
    "- 48-60: Outer Lip\n",
    "- 61-67: Inner Lip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Needed Points for Project - Points of Both the Eyes\n",
    "The image below is in reference to the previous image. We are here focusing on the points of the eyes. We will be using these points to calculate the eye aspect ratio.\n",
    "\n",
    "![Eye Mask Image](images/eyesmask.png \"Eye Mask Image\")\n",
    "\n",
    "\n",
    "##### Eye's Aspect Ratio Calculation:\n",
    "We shall write a function `calculateAspectRatioOfEye(eye)` to calculate the eye's aspect ratio. The eye's aspect ratio is the ratio of the vertical distance between the points of the eye and the horizontal distance between the extreme points of the eye.\n",
    "\n",
    "In the function `calculateAspectRatioOfEye(eye)`, the parameter `eye` is a list of 6 points of the eye. For the right eye, the list would be `[36, 37, 38, 39, 40, 41]` and for the left eye, the list would be `[42, 43, 44, 45, 46, 47]`.\n",
    "\n",
    "Vertical Distance between the points of the right eye would be the average of the distance between the points - `(37, 41)` and `(38, 40)`. Similarly, the vertical distance between the points of the left eye would be the average of the distance between the points - `(43, 47)` and `(44, 46)`.\n",
    "\n",
    "Horizontal Distance is comparatively simpler to calulate: It is the distance between the extreme points of the eye. For the right eye, it is the distance between the points `(36, 39)` and for the left eye, it is the distance between the points `(42, 45)`.\n",
    "\n",
    "The aspect ratio of the eye is the ratio of the vertical distance (which is the average of the two vertical distances calculated) and the horizontal distance.\n",
    "\n",
    "The function returns the aspect ratio of the eye."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial import distance\n",
    "\n",
    "# \"eye\" is a list of points that correspond to the eye landmarks\n",
    "def calculateAspectRatioOfEye(eye: list) -> float:\n",
    "    \"\"\"\n",
    "    Calculate the aspect ratio of an eye based on the distance between the top\n",
    "    and bottom of the eye and the distance between the left and right of\n",
    "    the eye\n",
    "    \"\"\"\n",
    "    eyeHeight_leftPart = distance.euclidean(eye[1], eye[5])\n",
    "    eyeHeight_rightPart = distance.euclidean(eye[2], eye[4])\n",
    "    eyeHeight = (eyeHeight_leftPart + eyeHeight_rightPart) / 2\n",
    "    \n",
    "    eyeWidth = distance.euclidean(eye[0], eye[3])\n",
    "    \n",
    "    return (eyeHeight / eyeWidth)\n",
    "# end function calculateAspectRatioOfEye()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Extracting the eye landmarks from the image and drawing the eye region bounding lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0) # 0 for default camera of the machine (PC)\n",
    "\n",
    "# while True:\n",
    "#     _, frame = cap.read()\n",
    "#     frame = cv2.flip(frame, 1) # mirror the webcam (1 - flip vertically)\n",
    "\n",
    "#     # Colour image not required for drowsiness detection (face detection)\n",
    "#     greyScaleImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Detect face using dlib's faceDetector\n",
    "#     faces = faceDetector(greyScaleImg) # list of rectangle coordinates of face\n",
    "\n",
    "#     # Iterate over the faces detected and get the eyes' landmarks\n",
    "#     for face in faces:\n",
    "#         faceLandmarks = dlibFaceLandmark(greyScaleImg, face)\n",
    "#         leftEye, rightEye = [], []\n",
    "\n",
    "#         # Get the landmarks of the right eye\n",
    "#         for n in range(36, 42):\n",
    "#             x_Coordinate = faceLandmarks.part(n).x\n",
    "#             y_Coordinate = faceLandmarks.part(n).y\n",
    "#             rightEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "#             # Draw a line surrounding the eye\n",
    "#             ## For that we need the next coordinates as well\n",
    "#             #### if n == 41, nextPoint = 36 -> to make a loop around the eye\n",
    "#             if n == 41:\n",
    "#                 nextPoint = 36\n",
    "#             else:\n",
    "#                 nextPoint = n + 1\n",
    "#             # end if-else\n",
    "\n",
    "#             x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "#             y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "#             cv2.line(frame, pt1=(x_Coordinate, y_Coordinate),\n",
    "#                      pt2=(x2_Coordinate, y2_Coordinate),\n",
    "#                      color=(0, 255, 0), thickness=1)\n",
    "#         # end for\n",
    "        \n",
    "#         # Get the landmarks of the left eye\n",
    "#         for n in range(42, 48):\n",
    "#             x_Coordinate = faceLandmarks.part(n).x\n",
    "#             y_Coordinate = faceLandmarks.part(n).y\n",
    "#             leftEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "#             # Draw a line surrounding the eye\n",
    "#             if n == 47:\n",
    "#                 nextPoint = 42\n",
    "#             else:\n",
    "#                 nextPoint = n + 1\n",
    "            \n",
    "#             x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "#             y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "#             cv2.line(frame, (x_Coordinate, y_Coordinate),\n",
    "#                      (x2_Coordinate, y2_Coordinate),\n",
    "#                      (0, 255, 255), 1)\n",
    "#         # end for\n",
    "\n",
    "#     cv2.imshow(\"Drowsiness Detection System\", frame)\n",
    "#     key = cv2.waitKey(10) # returns the ASCII value of the key pressed\n",
    "\n",
    "#     # Esc, 'Q', or 'q' exits the webcam\n",
    "#     # ord() returns the ASCII value of the parameter\n",
    "#     if key in [27, ord('q'), ord('Q')]:\n",
    "#         break\n",
    "# # end while\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Final Code for the Drowsiness Detection Project\n",
    "We shall calculate the aspect ratio of each eye and take its average and if the average is less than the threshold value (_here, we shall consider the threshold as 0.25_), we shall consider that the person is drowsy and sound an alarm.\n",
    "\n",
    "For the alarm we shall use the `pyttsx3` library which is a text-to-speech conversion library in Python. It works offline, and is compatible with both Python 2 and 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyttsx3\n",
    "\n",
    "# Initialising the pyttsx3 engine so that we can use it we can deliver an audio\n",
    "# message to the user if they are drowsy\n",
    "engine = pyttsx3.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import cv2\n",
    "\n",
    "\n",
    "# cap = cv2.VideoCapture(0) # 0 for default camera of the machine (PC)\n",
    "# cap.set(3, 640) # 3 -> CAP_PROP_FRAME_WIDTH\n",
    "# cap.set(4, 480) # 4 -> CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "# # Run webcam until 'Esc', 'Q', or 'q' is pressed\n",
    "# while True:\n",
    "#     _, frame = cap.read()\n",
    "#     frame = cv2.flip(frame, 1) # mirror the webcam (1 - flip vertically)\n",
    "\n",
    "#     # Colour image not required for drowsiness detection (face detection)\n",
    "#     greyScaleImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "#     # Detect face using dlib's faceDetector\n",
    "#     faces = faceDetector(greyScaleImg) # list of rectangle coordinates of face\n",
    "\n",
    "#     # Iterate over the faces detected and get the eyes' landmarks\n",
    "#     for face in faces:\n",
    "#         faceLandmarks = dlibFaceLandmark(greyScaleImg, face)\n",
    "#         leftEye, rightEye = [], []\n",
    "\n",
    "#         # Get the landmarks of the right eye\n",
    "#         for n in range(36, 42):\n",
    "#             x_Coordinate = faceLandmarks.part(n).x\n",
    "#             y_Coordinate = faceLandmarks.part(n).y\n",
    "#             rightEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "#             # Draw a line surrounding the eye\n",
    "#             ## For that we need the next coordinates as well\n",
    "#             #### if n == 41, nextPoint = 36 -> to make a loop around the eye\n",
    "#             if n == 41:\n",
    "#                 nextPoint = 36\n",
    "#             else:\n",
    "#                 nextPoint = n + 1\n",
    "#             # end if-else\n",
    "\n",
    "#             x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "#             y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "#             cv2.line(frame, pt1=(x_Coordinate, y_Coordinate),\n",
    "#                      pt2=(x2_Coordinate, y2_Coordinate),\n",
    "#                      color=(0, 255, 0), thickness=1)\n",
    "#         # end for\n",
    "        \n",
    "#         # Get the landmarks of the left eye\n",
    "#         for n in range(42, 48):\n",
    "#             x_Coordinate = faceLandmarks.part(n).x\n",
    "#             y_Coordinate = faceLandmarks.part(n).y\n",
    "#             leftEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "#             # Draw a line surrounding the eye\n",
    "#             if n == 47:\n",
    "#                 nextPoint = 42\n",
    "#             else:\n",
    "#                 nextPoint = n + 1\n",
    "            \n",
    "#             x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "#             y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "#             cv2.line(frame, (x_Coordinate, y_Coordinate),\n",
    "#                      (x2_Coordinate, y2_Coordinate),\n",
    "#                      (0, 255, 255), 1)\n",
    "#         # end for\n",
    "\n",
    "#         # Calculate the aspect ratio (AR) for both eyes and take average\n",
    "#         rightEyeAR = calculateAspectRatioOfEye(rightEye)\n",
    "#         leftEyeAR = calculateAspectRatioOfEye(leftEye)\n",
    "\n",
    "#         averageEyeAR = (rightEyeAR + leftEyeAR) / 2.0\n",
    "#         averageEyeAR = round(averageEyeAR, 2) # round of average to 2 decimal\n",
    "#                                               # places\n",
    "\n",
    "#         # Check against the threshold value for drowsiness\n",
    "#         if averageEyeAR < 0.25:\n",
    "#             cv2.putText(frame, text=\"Drowsy!!!\", org=(10, 30),\n",
    "#                         fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2,\n",
    "#                         color=(0, 0, 255), thickness=2)\n",
    "#             # Also call audio engine for alarm\n",
    "#             engine.say(\"Wake up, Sleepy Head!!!!!!\", \"wake-up-alert\")\n",
    "#             engine.runAndWait()\n",
    "#         # end if\n",
    "\n",
    "#     cv2.imshow(\"Drowsiness Detection System\", frame)\n",
    "#     key = cv2.waitKey(10) # returns the ASCII value of the key pressed\n",
    "\n",
    "#     # Esc, 'Q', or 'q' exits the webcam\n",
    "#     # ord() returns the ASCII value of the parameter\n",
    "#     if key in [27, ord('q'), ord('Q')]:\n",
    "#         break\n",
    "#     # end if\n",
    "# # end while\n",
    "\n",
    "# cap.release()\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "# # end of program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is working fine and great. But there's one issue we can try to solve here - the program sounds the alarm even if it catches the user merely blinking. One way to fix this is to maintain a counter of frames and if the eyes are closed for a threshold number of frames, we can assume that the person has fallen asleep and then sound the alarm. This threshold can be set depending on the user or the application. In this case, I have set it to 20, i.e., if the eyes remain closed for 20 consecutive frames, we assume that the person has fallen asleep."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "\n",
    "cap = cv2.VideoCapture(0) # 0 for default camera of the machine (PC)\n",
    "cap.set(3, 640) # 3 -> CAP_PROP_FRAME_WIDTH\n",
    "cap.set(4, 480) # 4 -> CAP_PROP_FRAME_HEIGHT\n",
    "\n",
    "frameCount = 0\n",
    "\n",
    "# Run webcam until 'Esc', 'Q', or 'q' is pressed\n",
    "while True:\n",
    "    _, frame = cap.read()\n",
    "    frame = cv2.flip(frame, 1) # mirror the webcam (1 - flip vertically)\n",
    "\n",
    "    # Colour image not required for drowsiness detection (face detection)\n",
    "    greyScaleImg = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Detect face using dlib's faceDetector\n",
    "    faces = faceDetector(greyScaleImg) # list of rectangle coordinates of face\n",
    "\n",
    "    # Iterate over the faces detected and get the eyes' landmarks\n",
    "    for face in faces:\n",
    "        faceLandmarks = dlibFaceLandmark(greyScaleImg, face)\n",
    "        leftEye, rightEye = [], []\n",
    "\n",
    "        # Get the landmarks of the right eye\n",
    "        for n in range(36, 42):\n",
    "            x_Coordinate = faceLandmarks.part(n).x\n",
    "            y_Coordinate = faceLandmarks.part(n).y\n",
    "            rightEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "            # Draw a line surrounding the eye\n",
    "            ## For that we need the next coordinates as well\n",
    "            #### if n == 41, nextPoint = 36 -> to make a loop around the eye\n",
    "            if n == 41:\n",
    "                nextPoint = 36\n",
    "            else:\n",
    "                nextPoint = n + 1\n",
    "            # end if-else\n",
    "\n",
    "            x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "            y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "            cv2.line(frame, pt1=(x_Coordinate, y_Coordinate),\n",
    "                     pt2=(x2_Coordinate, y2_Coordinate),\n",
    "                     color=(0, 255, 0), thickness=1)\n",
    "        # end for\n",
    "        \n",
    "        # Get the landmarks of the left eye\n",
    "        for n in range(42, 48):\n",
    "            x_Coordinate = faceLandmarks.part(n).x\n",
    "            y_Coordinate = faceLandmarks.part(n).y\n",
    "            leftEye.append((x_Coordinate, y_Coordinate))\n",
    "\n",
    "            # Draw a line surrounding the eye\n",
    "            if n == 47:\n",
    "                nextPoint = 42\n",
    "            else:\n",
    "                nextPoint = n + 1\n",
    "            \n",
    "            x2_Coordinate = faceLandmarks.part(nextPoint).x\n",
    "            y2_Coordinate = faceLandmarks.part(nextPoint).y\n",
    "            cv2.line(frame, (x_Coordinate, y_Coordinate),\n",
    "                     (x2_Coordinate, y2_Coordinate),\n",
    "                     (0, 255, 255), 1)\n",
    "        # end for\n",
    "\n",
    "        # Calculate the aspect ratio (AR) for both eyes and take average\n",
    "        rightEyeAR = calculateAspectRatioOfEye(rightEye)\n",
    "        leftEyeAR = calculateAspectRatioOfEye(leftEye)\n",
    "\n",
    "        averageEyeAR = (rightEyeAR + leftEyeAR) / 2.0\n",
    "        averageEyeAR = round(averageEyeAR, 2) # round of average to 2 decimal\n",
    "                                              # places\n",
    "\n",
    "        # Check against the threshold value for drowsiness\n",
    "        if averageEyeAR < 0.25:\n",
    "            # Check against the frame count to avoid false alarms like that \n",
    "            # when blinking\n",
    "            if frameCount >= 20:\n",
    "                cv2.putText(frame, text=\"Drowsy!!!\", org=(100, 100),\n",
    "                            fontFace=cv2.FONT_HERSHEY_SIMPLEX, fontScale=2,\n",
    "                            color=(0, 0, 255), thickness=2)\n",
    "                # Also call audio engine for alarm\n",
    "                engine.say(\"Wake up, Sleepy Head!!!!!!\", \"wake-up-alert\")\n",
    "                engine.runAndWait()\n",
    "            else:\n",
    "                frameCount += 1\n",
    "            # end if-else\n",
    "        else:\n",
    "            # Keep the framecount at zero if the eyes are open\n",
    "            frameCount = 0\n",
    "        # end if-else\n",
    "\n",
    "\n",
    "    cv2.imshow(\"Drowsiness Detection System\", frame)\n",
    "    key = cv2.waitKey(10) # returns the ASCII value of the key pressed\n",
    "\n",
    "    # Esc, 'Q', or 'q' exits the webcam\n",
    "    # ord() returns the ASCII value of the parameter\n",
    "    if key in [27, ord('q'), ord('Q')]:\n",
    "        break\n",
    "    # end if\n",
    "# end while\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# end of program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better. Though there are some irregularities based on the distance from the camera."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we don't need to detect the landmarks for every frame as it is an expensive operation. Instead, we can detect the landmarks after every n frames (I have used n=20 in this case) and hence saving a lot of computation power. This can be done as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dd_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
